
# DPQ 1-18-2016

**Last Friday's lecture claims that a "Bad Program" example with a single loop has a growth rate of O(n³). Justify that claim (i.e. why it is specifically that growth rate and not simply "slower than O(n²)". The sample counting behavior should provide a hint, if you can diagnose it.**

## Attempt #1

The overall intention of the source code attempts to "reset" the loop index counter
variable back to one, which is the initial cause for the algorithm to run on the
order of O(n^3). However, this causes a problem in the cases when the loop prematurely
stops the process when it finds that the element a[i] is > a[i+1], and therefore does not
check beyond the index i, therefore having to make excessive iterative loops to check all
the values present in the array.

As a concrete example, let's consider where this algorithm would actually have a run time of
n^3 with a given n. Say, n = 5 with an integer array that is structured as {5, 4, 3, 2, 1}
intentionally. When the loop is first executed, the first occurrence of the index variable
being reset would be where a[i], which is 5 is less than a[i+1] or 4. As a result it would
have to repeat the first pass of the bubble sort as an O(n^2) as opposed to O(n). And given
that we repeat the passes for n variables, this adds a factor of O(n) for every pass, and
therefore the entire runtime would be on the order of O(n^3).

> You do give a good example that yields the worst case behavior, but I'm not entirely convinced of what follows. After all, a single pass of a normal bubble sort goes through the entire array, and it is clear to see that if this code ever gets through the entire array, it will because the data is completely sorted, so it doesn't have to make any more passes! (Actually it becomes difficult to compare its behavior to a true bubble sort because of such a large operational difference) (1.0/1.0)